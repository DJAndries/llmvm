[package]
name = "llmvm-outsource"
version = "1.3.0"
edition = "2021"
description = "An llmvm backend which sends text and chat generation requests to known hosted language model providers."
authors.workspace = true
repository.workspace = true
license.workspace = true
categories = ["text-processing", "api-bindings", "command-line-utilities"]
keywords = ["llm", "ai", "openai", "huggingface"]

[dependencies]
clap = { workspace = true }
llmvm-backend-util = { version = "0.1", path = "../util" }
llmvm-outsource-lib = { version = "1.1", path = "../outsource-lib" }
llmvm-protocol = { version = "2.0", path = "../../protocol", features = ["http-server", "stdio-server"] }
llmvm-util = { version = "0.1", path = "../../util", features = ["config", "logging"] }
serde = { workspace = true, features = ["derive"] }
tokio = { workspace = true, features = ["rt", "macros", "net"] }
